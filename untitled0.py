# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1emza-eMCqrFK0OoCdwB0BnfAR9zckKqP
"""
from langchain.prompts import PromptTemplate
from langchain.llms import OpenAI
import streamlit as st
from langchain.chains import LLMChain
import replicate
import os
import numpy as np
from pydub import AudioSegment

sound = AudioSegment.from_mp3("sentence_5.mp3")
sound.export("sentence_5.wav", format="wav")

audio_file = open('sentence_1.wav', 'rb')
audio_bytes = audio_file.read()

os.environ["OPENAI_API_KEY"] = "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"

llm = OpenAI(temperature=0.9)
prompt = PromptTemplate(
    input_variables=["input"],
    template="Generate a story for a book about {input}?",
)

chain = LLMChain(llm=llm, prompt=prompt)

# Run the chain only specifying the input variable.
res = chain.run(st.text_input("Enter a topic: "))

llm = OpenAI(temperature=0.3)
prompt = PromptTemplate(
    input_variables=["res"],
    template="Write a summary for the following story in bullet points: {res}?",
)

chain = LLMChain(llm=llm, prompt=prompt)

summary = chain.run(res)

summary

from langchain.text_splitter import CharacterTextSplitter

text_splitter = CharacterTextSplitter(        
    chunk_size = 100,
    chunk_overlap  = 20,
    length_function = len,
)

texts = text_splitter.split_text(summary)
sum = []
for text in texts:
    split_text = text.split("\n")
    sum.extend(split_text)
print(sum)

from gtts import gTTS

language="en"

for i, text in enumerate(sum):
    speech = gTTS(text=text, lang=language, slow=False, tld="com.au")
    speech.save(f"sentence_{i}.mp3")

os.environ["REPLICATE_API_TOKEN"] = "a44df425f796d38fc6bd86e9e6d6a1aedf5ee0f3"

def generate_img(query):
  print("query: ", query)
  model = replicate.models.get("stability-ai/stable-diffusion")
  version = model.versions.get("f178fa7a1ae43a9a9af01b833b9d2ecf97b1bcb0acfd2dc5dd04895e042863f1")

  # https://replicate.com/pixray/text2image/versions/5c347a4bfa1d4523a58ae614c2194e15f2ae682b57e3797a5bb468920aa70ebf#input
  inputs = {
    # Input prompt
    'prompt': query,

    # Specify things to not see in the output
    # 'negative_prompt': ...,

    # Width of output image. Maximum size is 1024x768 or 768x1024 because
    # of memory limits
    'width': 768,

    # Height of output image. Maximum size is 1024x768 or 768x1024 because
    # of memory limits
    'height': 768,

    # Prompt strength when using init image. 1.0 corresponds to full
    # destruction of information in init image
    'prompt_strength': 0.8,

    # Number of images to output.
    # Range: 1 to 4
    'num_outputs': 1,

    # Number of denoising steps
    # Range: 1 to 500
    'num_inference_steps': 50,

    # Scale for classifier-free guidance
    # Range: 1 to 20
    'guidance_scale': 7.5,

    # Choose a scheduler.
    'scheduler': "DPMSolverMultistep",
  }
  img_list = []
  for text in sum:
    generated_img = generate_img(text)
    img_list.append(generated_img)
    print(img_list)


  # https://replicate.com/pixray/text2image/versions/5c347a4bfa1d4523a58ae614c2194e15f2ae682b57e3797a5bb468920aa70ebf#output-schema
  output = version.predict(**inputs)
  generated_image_batches = list(output)
  final_batch = generated_image_batches[-1]

  print(final_batch)
  return final_batch

sum = texts[0].split("\n")

# for i in sum:
#   print("i: ", i)
#   generate_img(i)

st.write("## Image + Audio")

st.audio(audio_bytes, format='audio/wav')
sample_rate = 44100  # 44100 samples per second
seconds = 2  # Note duration of 2 seconds
frequency_la = 440  # Our played note will be 440 Hz
# Generate array with seconds*sample_rate steps, ranging between 0 and seconds
t = np.linspace(0, seconds, seconds * sample_rate, False)
# Generate a 440 Hz sine wave
note_la = np.sin(frequency_la * t * 2 * np.pi)
st.image(
        "https://replicate.delivery/pbxt/fibn3C4EenuRDUwzeY3XEylX7JkDOUgBGJwbe4CgDePzpyZDC/out-0.png",
        width=400, # Manually Adjust the width of the image as per requirement
    )
st.audio(note_la, sample_rate=sample_rate)
